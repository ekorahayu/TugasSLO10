{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TugasSLO10.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1OnyDMREAurzyR3VatkVgdDE5-Q3Jx_qS",
      "authorship_tag": "ABX9TyMBYKeQa67DaT0I90WU5O4+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekorahayu/TugasSLO10/blob/main/TugasSLO10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_FqMmcTghCc",
        "outputId": "86ad8e80-4775-4ad9-b9f0-57b07b85ccd7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTY7a4L1pg60",
        "outputId": "a41f1652-e61f-44c2-b8a7-e8775e9c8e1b"
      },
      "source": [
        "cd /content/drive/My Drive/Colab Notebooks"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YksULMAapk1j",
        "outputId": "41022163-c999-45ae-b7f0-7c0dfdb4498c"
      },
      "source": [
        "ls"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \u001b[0m\u001b[01;34m3scenes\u001b[0m/                                   'Simple ANN in Python.ipynb'\n",
            "'Basic Python, Numpy and Matplotlib.ipynb'  'Testing Hasil.ipynb'\n",
            " \u001b[01;34mdataset\u001b[0m/                                    TugasSLO10.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGj0aldyq0b7"
      },
      "source": [
        "# import the necessary packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from PIL import Image\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30EvVy21sVVX",
        "outputId": "ad6d06f4-7fae-4a9b-db36-6344d3101ae8"
      },
      "source": [
        "# grab all image paths in the input dataset directory, then initialize\n",
        "# our list of images and corresponding class labels\n",
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = paths.list_images(\"dataset\")\n",
        "data = []\n",
        "labels = []"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa9ivZACs_EZ"
      },
      "source": [
        "# loop over our input images\n",
        "for imagePath in imagePaths:\n",
        "\t# load the input image from disk, resize it to 64x64 pixels, scale\n",
        "\t# the pixel intensities to the range [0, 1], and then update our\n",
        "\t# images list\n",
        "\timage = Image.open(imagePath)\n",
        "\timage = np.array(image.resize((224, 224))) / 255.0\n",
        "\tdata.append(image)\n",
        "\n",
        "\t# extract the class label from the file path and update the\n",
        "\t# labels list\n",
        "\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\tlabels.append(label)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaQThg41taAr",
        "outputId": "a59ab514-8121-46ff-fdec-0bdff0491511"
      },
      "source": [
        "print(labels)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_03', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_05', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_02', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_04', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01', 'GMB_01']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9aaA0mNtvyo"
      },
      "source": [
        "# encode the labels, converting them from strings to integers\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93vqkDYXxwRn",
        "outputId": "cafdf5d0-499e-496d-b051-f5c0fe1acd85"
      },
      "source": [
        "print(labels)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " ...\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbjVvSFq37Zs",
        "outputId": "c39b71a4-3306-4b62-cbb6-17703dfb29b3"
      },
      "source": [
        "# perform a training and testing split, using 75% of the data for\n",
        "# training and 25% for evaluation\n",
        "(trainX, testX, trainY, testY) = train_test_split(np.array(data),\tnp.array(labels), test_size=0.25)\n",
        "print(trainX.shape)\n",
        "print(testX.shape)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(438, 224, 224, 3)\n",
            "(146, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGwmS8Xj4Zbu"
      },
      "source": [
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import Model\n",
        "from keras.layers import GlobalAveragePooling2D, BatchNormalization"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9TzxbDT4gYb",
        "outputId": "2e9902ed-df13-4eaa-b663-812e55eb7e5f"
      },
      "source": [
        "from keras.layers import Dropout\n",
        "base_model = MobileNet(weights='imagenet', include_top=False)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "out = Dense(5, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=out)\n",
        "model.summary()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, None, None, 3)]   0         \n",
            "_________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)    (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, None, None, 32)    864       \n",
            "_________________________________________________________________\n",
            "conv1_bn (BatchNormalization (None, None, None, 32)    128       \n",
            "_________________________________________________________________\n",
            "conv1_relu (ReLU)            (None, None, None, 32)    0         \n",
            "_________________________________________________________________\n",
            "conv_dw_1 (DepthwiseConv2D)  (None, None, None, 32)    288       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_bn (BatchNormaliza (None, None, None, 32)    128       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_relu (ReLU)        (None, None, None, 32)    0         \n",
            "_________________________________________________________________\n",
            "conv_pw_1 (Conv2D)           (None, None, None, 64)    2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_1_bn (BatchNormaliza (None, None, None, 64)    256       \n",
            "_________________________________________________________________\n",
            "conv_pw_1_relu (ReLU)        (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv_pad_2 (ZeroPadding2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv_dw_2 (DepthwiseConv2D)  (None, None, None, 64)    576       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_bn (BatchNormaliza (None, None, None, 64)    256       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_relu (ReLU)        (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv_pw_2 (Conv2D)           (None, None, None, 128)   8192      \n",
            "_________________________________________________________________\n",
            "conv_pw_2_bn (BatchNormaliza (None, None, None, 128)   512       \n",
            "_________________________________________________________________\n",
            "conv_pw_2_relu (ReLU)        (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_3 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
            "_________________________________________________________________\n",
            "conv_dw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_3 (Conv2D)           (None, None, None, 128)   16384     \n",
            "_________________________________________________________________\n",
            "conv_pw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
            "_________________________________________________________________\n",
            "conv_pw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "conv_pad_4 (ZeroPadding2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_4 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_4_bn (BatchNormaliza (None, None, None, 128)   512       \n",
            "_________________________________________________________________\n",
            "conv_dw_4_relu (ReLU)        (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_4 (Conv2D)           (None, None, None, 256)   32768     \n",
            "_________________________________________________________________\n",
            "conv_pw_4_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_4_relu (ReLU)        (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_5 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_5 (Conv2D)           (None, None, None, 256)   65536     \n",
            "_________________________________________________________________\n",
            "conv_pw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "conv_pad_6 (ZeroPadding2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_6 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_relu (ReLU)        (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_6 (Conv2D)           (None, None, None, 512)   131072    \n",
            "_________________________________________________________________\n",
            "conv_pw_6_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_6_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_7 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_7 (Conv2D)           (None, None, None, 512)   262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_8 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_8 (Conv2D)           (None, None, None, 512)   262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_9 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_9 (Conv2D)           (None, None, None, 512)   262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_10 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_10 (Conv2D)          (None, None, None, 512)   262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_11 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_11 (Conv2D)          (None, None, None, 512)   262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pad_12 (ZeroPadding2D)  (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_12 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_relu (ReLU)       (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_12 (Conv2D)          (None, None, None, 1024)  524288    \n",
            "_________________________________________________________________\n",
            "conv_pw_12_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_12_relu (ReLU)       (None, None, None, 1024)  0         \n",
            "_________________________________________________________________\n",
            "conv_dw_13 (DepthwiseConv2D) (None, None, None, 1024)  9216      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
            "_________________________________________________________________\n",
            "conv_pw_13 (Conv2D)          (None, None, None, 1024)  1048576   \n",
            "_________________________________________________________________\n",
            "conv_pw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 5)                 2565      \n",
            "=================================================================\n",
            "Total params: 3,760,325\n",
            "Trainable params: 3,736,389\n",
            "Non-trainable params: 23,936\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9vlyNJL45cd"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss',\n",
        "                   patience=5,\n",
        "                   mode='auto',\n",
        "                   restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('best_weight_scene_mobileNet.h5',\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             mode='auto',)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJqK72Nl5MYq"
      },
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "\n",
        "model = Sequential(\n",
        "    [\n",
        "        Flatten(input_shape=(64*64*3,)),\n",
        "        Dense(100, activation=\"relu\", name=\"layer1\"),\n",
        "        Dense(16, activation=\"relu\", name=\"layer2\"),\n",
        "        Dense(16, activation=\"relu\", name=\"layer3\"),\n",
        "        Dense(5, activation = \"relu\", name=\"layer4\"),\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_DE6yaS5OF1",
        "outputId": "b0ddf34b-e4ee-4bd0-da76-cea143dc844b"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, None, None, 3)]   0         \n",
            "_________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)    (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, None, None, 32)    864       \n",
            "_________________________________________________________________\n",
            "conv1_bn (BatchNormalization (None, None, None, 32)    128       \n",
            "_________________________________________________________________\n",
            "conv1_relu (ReLU)            (None, None, None, 32)    0         \n",
            "_________________________________________________________________\n",
            "conv_dw_1 (DepthwiseConv2D)  (None, None, None, 32)    288       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_bn (BatchNormaliza (None, None, None, 32)    128       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_relu (ReLU)        (None, None, None, 32)    0         \n",
            "_________________________________________________________________\n",
            "conv_pw_1 (Conv2D)           (None, None, None, 64)    2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_1_bn (BatchNormaliza (None, None, None, 64)    256       \n",
            "_________________________________________________________________\n",
            "conv_pw_1_relu (ReLU)        (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv_pad_2 (ZeroPadding2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv_dw_2 (DepthwiseConv2D)  (None, None, None, 64)    576       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_bn (BatchNormaliza (None, None, None, 64)    256       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_relu (ReLU)        (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv_pw_2 (Conv2D)           (None, None, None, 128)   8192      \n",
            "_________________________________________________________________\n",
            "conv_pw_2_bn (BatchNormaliza (None, None, None, 128)   512       \n",
            "_________________________________________________________________\n",
            "conv_pw_2_relu (ReLU)        (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_3 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
            "_________________________________________________________________\n",
            "conv_dw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_3 (Conv2D)           (None, None, None, 128)   16384     \n",
            "_________________________________________________________________\n",
            "conv_pw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
            "_________________________________________________________________\n",
            "conv_pw_3_relu (ReLU)        (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "conv_pad_4 (ZeroPadding2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_4 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_4_bn (BatchNormaliza (None, None, None, 128)   512       \n",
            "_________________________________________________________________\n",
            "conv_dw_4_relu (ReLU)        (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_4 (Conv2D)           (None, None, None, 256)   32768     \n",
            "_________________________________________________________________\n",
            "conv_pw_4_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_4_relu (ReLU)        (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_5 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_5 (Conv2D)           (None, None, None, 256)   65536     \n",
            "_________________________________________________________________\n",
            "conv_pw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_5_relu (ReLU)        (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "conv_pad_6 (ZeroPadding2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_6 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_relu (ReLU)        (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_6 (Conv2D)           (None, None, None, 512)   131072    \n",
            "_________________________________________________________________\n",
            "conv_pw_6_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_6_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_7 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_7 (Conv2D)           (None, None, None, 512)   262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_7_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_8 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_8 (Conv2D)           (None, None, None, 512)   262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_8_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_9 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_9 (Conv2D)           (None, None, None, 512)   262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_9_relu (ReLU)        (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_10 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_10 (Conv2D)          (None, None, None, 512)   262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_10_relu (ReLU)       (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_11 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_11 (Conv2D)          (None, None, None, 512)   262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_11_relu (ReLU)       (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pad_12 (ZeroPadding2D)  (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_dw_12 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_relu (ReLU)       (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "conv_pw_12 (Conv2D)          (None, None, None, 1024)  524288    \n",
            "_________________________________________________________________\n",
            "conv_pw_12_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_12_relu (ReLU)       (None, None, None, 1024)  0         \n",
            "_________________________________________________________________\n",
            "conv_dw_13 (DepthwiseConv2D) (None, None, None, 1024)  9216      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
            "_________________________________________________________________\n",
            "conv_pw_13 (Conv2D)          (None, None, None, 1024)  1048576   \n",
            "_________________________________________________________________\n",
            "conv_pw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_13_relu (ReLU)       (None, None, None, 1024)  0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 5)                 2565      \n",
            "=================================================================\n",
            "Total params: 3,760,325\n",
            "Trainable params: 3,736,389\n",
            "Non-trainable params: 23,936\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVgwSySE5XwR",
        "outputId": "dad8932e-99c4-46af-8a71-0095191436f3"
      },
      "source": [
        "# train the model using the Adam optimizer\n",
        "print(\"[INFO] training network...\")\n",
        "opt = Adam(lr=1e-4, decay=1e-3 / 50)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=50, batch_size=32, callbacks=[es, checkpoint])"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training network...\n",
            "Epoch 1/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 1.5125 - accuracy: 0.3790\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.49315, saving model to best_weight_scene_mobileNet.h5\n",
            "14/14 [==============================] - 81s 6s/step - loss: 1.5125 - accuracy: 0.3790 - val_loss: 1.4381 - val_accuracy: 0.4932\n",
            "Epoch 2/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.6082 - accuracy: 0.7922\n",
            "Epoch 00002: val_accuracy improved from 0.49315 to 0.52740, saving model to best_weight_scene_mobileNet.h5\n",
            "14/14 [==============================] - 83s 6s/step - loss: 0.6082 - accuracy: 0.7922 - val_loss: 1.3417 - val_accuracy: 0.5274\n",
            "Epoch 3/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.2561 - accuracy: 0.9361\n",
            "Epoch 00003: val_accuracy improved from 0.52740 to 0.60959, saving model to best_weight_scene_mobileNet.h5\n",
            "14/14 [==============================] - 83s 6s/step - loss: 0.2561 - accuracy: 0.9361 - val_loss: 1.2531 - val_accuracy: 0.6096\n",
            "Epoch 4/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.1513 - accuracy: 0.9726\n",
            "Epoch 00004: val_accuracy improved from 0.60959 to 0.63014, saving model to best_weight_scene_mobileNet.h5\n",
            "14/14 [==============================] - 83s 6s/step - loss: 0.1513 - accuracy: 0.9726 - val_loss: 1.1166 - val_accuracy: 0.6301\n",
            "Epoch 5/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 0.9954\n",
            "Epoch 00005: val_accuracy improved from 0.63014 to 0.69178, saving model to best_weight_scene_mobileNet.h5\n",
            "14/14 [==============================] - 83s 6s/step - loss: 0.0933 - accuracy: 0.9954 - val_loss: 0.8786 - val_accuracy: 0.6918\n",
            "Epoch 6/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 0.9932\n",
            "Epoch 00006: val_accuracy improved from 0.69178 to 0.74658, saving model to best_weight_scene_mobileNet.h5\n",
            "14/14 [==============================] - 83s 6s/step - loss: 0.0714 - accuracy: 0.9932 - val_loss: 0.7522 - val_accuracy: 0.7466\n",
            "Epoch 7/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9977\n",
            "Epoch 00007: val_accuracy improved from 0.74658 to 0.81507, saving model to best_weight_scene_mobileNet.h5\n",
            "14/14 [==============================] - 82s 6s/step - loss: 0.0471 - accuracy: 0.9977 - val_loss: 0.5957 - val_accuracy: 0.8151\n",
            "Epoch 8/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9977\n",
            "Epoch 00008: val_accuracy did not improve from 0.81507\n",
            "14/14 [==============================] - 80s 6s/step - loss: 0.0391 - accuracy: 0.9977 - val_loss: 0.5423 - val_accuracy: 0.8151\n",
            "Epoch 9/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9954\n",
            "Epoch 00009: val_accuracy improved from 0.81507 to 0.82877, saving model to best_weight_scene_mobileNet.h5\n",
            "14/14 [==============================] - 83s 6s/step - loss: 0.0330 - accuracy: 0.9954 - val_loss: 0.4739 - val_accuracy: 0.8288\n",
            "Epoch 10/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 1.0000\n",
            "Epoch 00010: val_accuracy improved from 0.82877 to 0.84932, saving model to best_weight_scene_mobileNet.h5\n",
            "14/14 [==============================] - 83s 6s/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.4163 - val_accuracy: 0.8493\n",
            "Epoch 11/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9977\n",
            "Epoch 00011: val_accuracy did not improve from 0.84932\n",
            "14/14 [==============================] - 80s 6s/step - loss: 0.0247 - accuracy: 0.9977 - val_loss: 0.3739 - val_accuracy: 0.8493\n",
            "Epoch 12/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 1.0000\n",
            "Epoch 00012: val_accuracy improved from 0.84932 to 0.86986, saving model to best_weight_scene_mobileNet.h5\n",
            "14/14 [==============================] - 83s 6s/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.3197 - val_accuracy: 0.8699\n",
            "Epoch 13/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 1.0000\n",
            "Epoch 00013: val_accuracy improved from 0.86986 to 0.88356, saving model to best_weight_scene_mobileNet.h5\n",
            "14/14 [==============================] - 83s 6s/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.8836\n",
            "Epoch 14/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 1.0000\n",
            "Epoch 00014: val_accuracy improved from 0.88356 to 0.89726, saving model to best_weight_scene_mobileNet.h5\n",
            "14/14 [==============================] - 83s 6s/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.8973\n",
            "Epoch 15/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 1.0000\n",
            "Epoch 00015: val_accuracy improved from 0.89726 to 0.91096, saving model to best_weight_scene_mobileNet.h5\n",
            "14/14 [==============================] - 83s 6s/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9110\n",
            "Epoch 16/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 1.0000\n",
            "Epoch 00016: val_accuracy improved from 0.91096 to 0.91781, saving model to best_weight_scene_mobileNet.h5\n",
            "14/14 [==============================] - 83s 6s/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9178\n",
            "Epoch 17/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 1.0000\n",
            "Epoch 00017: val_accuracy improved from 0.91781 to 0.93836, saving model to best_weight_scene_mobileNet.h5\n",
            "14/14 [==============================] - 83s 6s/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.9384\n",
            "Epoch 18/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 00018: val_accuracy did not improve from 0.93836\n",
            "14/14 [==============================] - 80s 6s/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.9384\n",
            "Epoch 19/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 1.0000\n",
            "Epoch 00019: val_accuracy improved from 0.93836 to 0.94521, saving model to best_weight_scene_mobileNet.h5\n",
            "14/14 [==============================] - 83s 6s/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9452\n",
            "Epoch 20/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 1.0000\n",
            "Epoch 00020: val_accuracy improved from 0.94521 to 0.95205, saving model to best_weight_scene_mobileNet.h5\n",
            "14/14 [==============================] - 84s 6s/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 0.9521\n",
            "Epoch 21/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 1.0000\n",
            "Epoch 00021: val_accuracy improved from 0.95205 to 0.96575, saving model to best_weight_scene_mobileNet.h5\n",
            "14/14 [==============================] - 82s 6s/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 0.9658\n",
            "Epoch 22/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 00022: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 80s 6s/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9658\n",
            "Epoch 23/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 00023: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 80s 6s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1679 - val_accuracy: 0.9658\n",
            "Epoch 24/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000\n",
            "Epoch 00024: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 80s 6s/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1552 - val_accuracy: 0.9658\n",
            "Epoch 25/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 00025: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 81s 6s/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9658\n",
            "Epoch 26/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 00026: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 81s 6s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1549 - val_accuracy: 0.9589\n",
            "Epoch 27/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 00027: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 81s 6s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1500 - val_accuracy: 0.9589\n",
            "Epoch 28/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 00028: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 82s 6s/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1446 - val_accuracy: 0.9658\n",
            "Epoch 29/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 00029: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 81s 6s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 0.9658\n",
            "Epoch 30/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 00030: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 82s 6s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9658\n",
            "Epoch 31/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 00031: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 82s 6s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1431 - val_accuracy: 0.9658\n",
            "Epoch 32/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 00032: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 82s 6s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9658\n",
            "Epoch 33/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 00033: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 81s 6s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1395 - val_accuracy: 0.9658\n",
            "Epoch 34/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 00034: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 81s 6s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1439 - val_accuracy: 0.9658\n",
            "Epoch 35/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 00035: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 81s 6s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 0.9658\n",
            "Epoch 36/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 00036: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 81s 6s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1439 - val_accuracy: 0.9658\n",
            "Epoch 37/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 00037: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 81s 6s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9658\n",
            "Epoch 38/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 00038: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 81s 6s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 0.9658\n",
            "Epoch 39/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 00039: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 81s 6s/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 0.9658\n",
            "Epoch 40/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 00040: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 80s 6s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9658\n",
            "Epoch 41/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 00041: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 80s 6s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1301 - val_accuracy: 0.9658\n",
            "Epoch 42/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 00042: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 80s 6s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9521\n",
            "Epoch 43/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 00043: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 80s 6s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.9521\n",
            "Epoch 44/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 00044: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 80s 6s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1371 - val_accuracy: 0.9521\n",
            "Epoch 45/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 00045: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 80s 6s/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9589\n",
            "Epoch 46/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 00046: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 80s 6s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9658\n",
            "Epoch 47/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 00047: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 80s 6s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9658\n",
            "Epoch 48/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 00048: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 80s 6s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1269 - val_accuracy: 0.9658\n",
            "Epoch 49/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 00049: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 80s 6s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1317 - val_accuracy: 0.9658\n",
            "Epoch 50/50\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000    \n",
            "Epoch 00050: val_accuracy did not improve from 0.96575\n",
            "14/14 [==============================] - 80s 6s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1295 - val_accuracy: 0.9658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZQLaCdq5jUA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "96396219-1fa3-4d29-bbe5-bebd7a776db1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(H.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(H.history['accuracy'])\n",
        "plt.plot(H.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(H.history['loss'])\n",
        "plt.plot(H.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7CIk5vw5_RW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "110d8f92-6031-48d0-9f6d-974d30159ca3"
      },
      "source": [
        "# evaluate the network\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(testX, batch_size=32)\n",
        "#print(predictions)\n",
        "print(classification_report(testY.argmax(axis=1), predictions.argmax(axis=1), target_names=lb.classes_))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      GMB_01       0.93      0.96      0.95        28\n",
            "      GMB_02       1.00      1.00      1.00        33\n",
            "      GMB_03       0.93      0.93      0.93        28\n",
            "      GMB_04       1.00      0.96      0.98        28\n",
            "      GMB_05       0.97      0.97      0.97        29\n",
            "\n",
            "    accuracy                           0.97       146\n",
            "   macro avg       0.97      0.96      0.96       146\n",
            "weighted avg       0.97      0.97      0.97       146\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1GJcAg-6BUC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69856226-8260-4ed3-a3a1-b4ba18054a5a"
      },
      "source": [
        "model.save('nnmodel_scene')"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: nnmodel_scene/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_8BvH5m6OQo"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "image1='.jpg'"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IpSlz3x6Wrk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "986c7cac-e1b3-49a4-f6e3-ee567835d2d7"
      },
      "source": [
        "img_array = cv2.imread(image1)\n",
        "plt.imshow(img_array)\n",
        "plt.show()\n",
        "print(type(img_array))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-616fc5e4b8b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2651\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2652\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5626\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    692\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[1;32m    693\u001b[0m             raise TypeError(\"Image data of dtype {} cannot be converted to \"\n\u001b[0;32m--> 694\u001b[0;31m                             \"float\".format(self._A.dtype))\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         if not (self._A.ndim == 2\n",
            "\u001b[0;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzrKgZkj6abw"
      },
      "source": [
        "image_testing = Image.open('IMG_20200814_131553_HDR.jpg')\n",
        "image_testing = np.array(image_testing.resize((64, 64))) / 255.0\n",
        "image_testing.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS_WxR1U6fux"
      },
      "source": [
        "image_testing = np.expand_dims(image_testing, axis=0)\n",
        "print(image_testing.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8TQS0DT6jJh"
      },
      "source": [
        "output = model.predict(image_testing, 1)\n",
        "print(output)\n",
        "print(lb.classes_[output.argmax(axis=1)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNkVexN46kW3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}